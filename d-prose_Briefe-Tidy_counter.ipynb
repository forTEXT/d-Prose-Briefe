{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2376438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796a221",
   "metadata": {},
   "source": [
    "first we want to get an overview on the corpus by looking at the metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1a3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guhr/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#open the metadata file\n",
    "# Path to your csv file\n",
    "metadata_file = 'd-prose_V2_norm_year.csv'\n",
    "\n",
    "# Read the csv file and load it into a DataFrame\n",
    "#df = pd.read_csv(metadata_file) #in the case of irregularities in the data, you can skip the rows with no content\n",
    "#the delimiter should be indicated as \";\" if it is not the default: ','\n",
    "df = pd.read_csv(metadata_file, delimiter=';', error_bad_lines=False, na_values=['NA', 'NaN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee16b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "Repositorium\n",
      "Vorname Autor\n",
      "Nachname Autor\n",
      "Nationalität\n",
      "Pseudonym/Anderer Name\n",
      "Gesamtname Autor\n",
      "Geburtsjahr\n",
      "Sterbejahr\n",
      "Autor:innengender\n",
      "Titel\n",
      "Dateiname\n",
      "verwendetes Datum\n",
      "Wörter\n",
      "Typen\n",
      "norm_year\n"
     ]
    }
   ],
   "source": [
    "#get information on the metadata table\n",
    "\n",
    "# Get the headers of each column\n",
    "headers = df.columns.tolist()\n",
    "\n",
    "# Print the column headers\n",
    "for header in headers:\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f4d0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Repositorium</th>\n",
       "      <th>Vorname Autor</th>\n",
       "      <th>Nachname Autor</th>\n",
       "      <th>Nationalität</th>\n",
       "      <th>Pseudonym/Anderer Name</th>\n",
       "      <th>Gesamtname Autor</th>\n",
       "      <th>Geburtsjahr</th>\n",
       "      <th>Sterbejahr</th>\n",
       "      <th>Autor:innengender</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Dateiname</th>\n",
       "      <th>verwendetes Datum</th>\n",
       "      <th>Wörter</th>\n",
       "      <th>Typen</th>\n",
       "      <th>norm_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>Achleitner</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arthur Achleitner</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>1927</td>\n",
       "      <td>male</td>\n",
       "      <td>Das Schloß im Moor</td>\n",
       "      <td>Achleitner_Arthur_Das_Schloss_im_Moor</td>\n",
       "      <td>1903</td>\n",
       "      <td>50886</td>\n",
       "      <td>9654</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>Achleitner</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arthur Achleitner</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>1927</td>\n",
       "      <td>male</td>\n",
       "      <td>Der Finanzer</td>\n",
       "      <td>Achleitner_Arthur_Der_Finanzer</td>\n",
       "      <td>1903</td>\n",
       "      <td>23933</td>\n",
       "      <td>5941</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>Karl</td>\n",
       "      <td>Adolph</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karl Adolph</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>1931</td>\n",
       "      <td>male</td>\n",
       "      <td>Haus Nummer 37</td>\n",
       "      <td>Adolph_Karl_Haus_Nummer</td>\n",
       "      <td>1908</td>\n",
       "      <td>102735</td>\n",
       "      <td>17038</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>Karl</td>\n",
       "      <td>Adolph</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karl Adolph</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>1931</td>\n",
       "      <td>male</td>\n",
       "      <td>Schackerl</td>\n",
       "      <td>Adolph_Karl_Schackerl</td>\n",
       "      <td>1912</td>\n",
       "      <td>39838</td>\n",
       "      <td>9266</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>Karl</td>\n",
       "      <td>Adolph</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karl Adolph</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>1931</td>\n",
       "      <td>male</td>\n",
       "      <td>Töchter</td>\n",
       "      <td>Adolph_Karl_Toechter</td>\n",
       "      <td>1914</td>\n",
       "      <td>87720</td>\n",
       "      <td>15569</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>textgrid</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Altenberg</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Altenberg</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>male</td>\n",
       "      <td>Aus dem Tagebuche der edlen Miss Madrilene</td>\n",
       "      <td>Altenberg_Peter_Aus_dem_Tagebuche</td>\n",
       "      <td>1901</td>\n",
       "      <td>1879</td>\n",
       "      <td>769</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>textgrid</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Altenberg</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Altenberg</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>male</td>\n",
       "      <td>Aus unseren Tränen wird Weisheit; aber aus eur...</td>\n",
       "      <td>Altenberg_Peter_Aus_unseren_Traenen</td>\n",
       "      <td>1908</td>\n",
       "      <td>1442</td>\n",
       "      <td>669</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>textgrid</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Altenberg</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Altenberg</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>male</td>\n",
       "      <td>De Libertate</td>\n",
       "      <td>Altenberg_Peter_De_Libertate</td>\n",
       "      <td>1901</td>\n",
       "      <td>1310</td>\n",
       "      <td>654</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>textgrid</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Altenberg</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Altenberg</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>male</td>\n",
       "      <td>Der Besuch</td>\n",
       "      <td>Altenberg_Peter_Der_Besuch</td>\n",
       "      <td>1896</td>\n",
       "      <td>1156</td>\n",
       "      <td>557</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>textgrid</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Altenberg</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Altenberg</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>male</td>\n",
       "      <td>Der Hofmeister</td>\n",
       "      <td>Altenberg_Peter_Der_Hofmeister</td>\n",
       "      <td>1896</td>\n",
       "      <td>1280</td>\n",
       "      <td>585</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Repositorium Vorname Autor Nachname Autor Nationalität  \\\n",
       "0   1    gutenberg        Arthur     Achleitner  Deutschland   \n",
       "1   2    gutenberg        Arthur     Achleitner  Deutschland   \n",
       "2   3    gutenberg          Karl         Adolph   Österreich   \n",
       "3   4    gutenberg          Karl         Adolph   Österreich   \n",
       "4   5    gutenberg          Karl         Adolph   Österreich   \n",
       "5   6     textgrid         Peter      Altenberg  Deutschland   \n",
       "6   7     textgrid         Peter      Altenberg  Deutschland   \n",
       "7   8     textgrid         Peter      Altenberg  Deutschland   \n",
       "8   9     textgrid         Peter      Altenberg  Deutschland   \n",
       "9  10     textgrid         Peter      Altenberg  Deutschland   \n",
       "\n",
       "  Pseudonym/Anderer Name   Gesamtname Autor  Geburtsjahr Sterbejahr  \\\n",
       "0                    NaN  Arthur Achleitner       1858.0       1927   \n",
       "1                    NaN  Arthur Achleitner       1858.0       1927   \n",
       "2                    NaN        Karl Adolph       1869.0       1931   \n",
       "3                    NaN        Karl Adolph       1869.0       1931   \n",
       "4                    NaN        Karl Adolph       1869.0       1931   \n",
       "5                    NaN    Peter Altenberg       1890.0       1960   \n",
       "6                    NaN    Peter Altenberg       1890.0       1960   \n",
       "7                    NaN    Peter Altenberg       1890.0       1960   \n",
       "8                    NaN    Peter Altenberg       1890.0       1960   \n",
       "9                    NaN    Peter Altenberg       1890.0       1960   \n",
       "\n",
       "  Autor:innengender                                              Titel  \\\n",
       "0              male                                 Das Schloß im Moor   \n",
       "1              male                                       Der Finanzer   \n",
       "2              male                                     Haus Nummer 37   \n",
       "3              male                                          Schackerl   \n",
       "4              male                                            Töchter   \n",
       "5              male         Aus dem Tagebuche der edlen Miss Madrilene   \n",
       "6              male  Aus unseren Tränen wird Weisheit; aber aus eur...   \n",
       "7              male                                       De Libertate   \n",
       "8              male                                         Der Besuch   \n",
       "9              male                                     Der Hofmeister   \n",
       "\n",
       "                               Dateiname verwendetes Datum  Wörter  Typen  \\\n",
       "0  Achleitner_Arthur_Das_Schloss_im_Moor              1903   50886   9654   \n",
       "1         Achleitner_Arthur_Der_Finanzer              1903   23933   5941   \n",
       "2                Adolph_Karl_Haus_Nummer              1908  102735  17038   \n",
       "3                  Adolph_Karl_Schackerl              1912   39838   9266   \n",
       "4                   Adolph_Karl_Toechter              1914   87720  15569   \n",
       "5      Altenberg_Peter_Aus_dem_Tagebuche              1901    1879    769   \n",
       "6    Altenberg_Peter_Aus_unseren_Traenen              1908    1442    669   \n",
       "7           Altenberg_Peter_De_Libertate              1901    1310    654   \n",
       "8             Altenberg_Peter_Der_Besuch              1896    1156    557   \n",
       "9         Altenberg_Peter_Der_Hofmeister              1896    1280    585   \n",
       "\n",
       "   norm_year  \n",
       "0       1903  \n",
       "1       1903  \n",
       "2       1908  \n",
       "3       1912  \n",
       "4       1914  \n",
       "5       1901  \n",
       "6       1908  \n",
       "7       1901  \n",
       "8       1896  \n",
       "9       1896  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 10 lines of the data frame\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e914662",
   "metadata": {},
   "source": [
    "## What next?\n",
    "Now we want to look directly into the corpus by opening the folder with the plain text files and creating a dataframe out of the filename in the first column and the plain text of the file in the second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2f924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['von_Wolzogen_Ernst_Vom_Peperl_und von andern_Raritaeten_Der_Raritaetenliabhaber.txt',\n",
       " 'Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuettel.txt',\n",
       " 'Anzengruber_Ludwig_Kalendergeschichten_Treff-Ass.txt',\n",
       " 'Fontane_Theodor_Cecile.txt',\n",
       " 'Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutterstadt.txt',\n",
       " 'Hollaender_Felix_Die_Briefe_des_Fraeulein.txt',\n",
       " 'Heyse_Paul_Gegen_den_Strom.txt',\n",
       " 'Federer_Heinrich_Umbrische_Reisegeschichtlein_San_Benedettos_Dornen.txt',\n",
       " 'Groller_Balduin_Detektiv_Dagobert_Eine_teure_Depesche.txt',\n",
       " 'von_Zobeltitz_Fedor_Das_Heiratsjahr.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a corpus by loading all the txt files from the chosen directory \n",
    "# and list the names of the first 10 txt files \n",
    "corpus = os.listdir('d-prose_1870-1920_V.2.0/')\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6868e68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511\n"
     ]
    }
   ],
   "source": [
    "# Print how many txt files are in the corpus\n",
    "corpus_length = len(corpus)\n",
    "print(corpus_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8fcace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary for preparation of the conversion of the txt-file-corpus to a data frame\n",
    "empty_dictionary = {}\n",
    "\n",
    "# Loop through the folder of documents to open and read each one\n",
    "for document in corpus:\n",
    "    with open('d-prose_1870-1920_V.2.0/' + document, 'r', encoding = 'utf-8') as to_open:\n",
    "         empty_dictionary[document] = to_open.read()\n",
    "\n",
    "# Populate the data frame with two columns: file name and document text\n",
    "d_prose_texts = (pd.DataFrame.from_dict(empty_dictionary, \n",
    "                                       orient = 'index')\n",
    "                .reset_index().rename(index = str, \n",
    "                                      columns = {'index': 'file_name', 0: 'document_text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9caaa47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>document_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...</td>\n",
       "      <td>Der Raritätenliabhaber\\n\\n»Ja, grüaß Eahna Got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...</td>\n",
       "      <td>Die Neunte in Klütenbüttel\\n\\nIn Klütenbüttel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anzengruber_Ludwig_Kalendergeschichten_Treff-A...</td>\n",
       "      <td>Treff-Aß\\n\\nGibt es ein Buch des Schicksals, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fontane_Theodor_Cecile.txt</td>\n",
       "      <td>Cécile\\n\\nErstes Kapitel\\n\\n»Thale. Zweiter…«\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...</td>\n",
       "      <td>Die Perlmutterstadt\\n\\nBekanntlich weilt der u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hollaender_Felix_Die_Briefe_des_Fraeulein.txt</td>\n",
       "      <td>Die Briefe des Fräulein Brandt\\n\\nIserbaude, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heyse_Paul_Gegen_den_Strom.txt</td>\n",
       "      <td>Gegen den Strom\\n\\nErstes Kapitel.\\n\\nEs war z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Federer_Heinrich_Umbrische_Reisegeschichtlein_...</td>\n",
       "      <td>San Benedettos Dornen und San Francescos Rosen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Groller_Balduin_Detektiv_Dagobert_Eine_teure_D...</td>\n",
       "      <td>Eine teure Depesche\\n\\nSie saßen wieder zu dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>von_Zobeltitz_Fedor_Das_Heiratsjahr.txt</td>\n",
       "      <td>Das Heiratsjahr.\\n\\nErstes Kapitel.\\n\\nIn welc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0  von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...   \n",
       "1  Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...   \n",
       "2  Anzengruber_Ludwig_Kalendergeschichten_Treff-A...   \n",
       "3                         Fontane_Theodor_Cecile.txt   \n",
       "4  Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...   \n",
       "5      Hollaender_Felix_Die_Briefe_des_Fraeulein.txt   \n",
       "6                     Heyse_Paul_Gegen_den_Strom.txt   \n",
       "7  Federer_Heinrich_Umbrische_Reisegeschichtlein_...   \n",
       "8  Groller_Balduin_Detektiv_Dagobert_Eine_teure_D...   \n",
       "9            von_Zobeltitz_Fedor_Das_Heiratsjahr.txt   \n",
       "\n",
       "                                       document_text  \n",
       "0  Der Raritätenliabhaber\\n\\n»Ja, grüaß Eahna Got...  \n",
       "1  Die Neunte in Klütenbüttel\\n\\nIn Klütenbüttel ...  \n",
       "2  Treff-Aß\\n\\nGibt es ein Buch des Schicksals, s...  \n",
       "3  Cécile\\n\\nErstes Kapitel\\n\\n»Thale. Zweiter…«\\...  \n",
       "4  Die Perlmutterstadt\\n\\nBekanntlich weilt der u...  \n",
       "5  Die Briefe des Fräulein Brandt\\n\\nIserbaude, 7...  \n",
       "6  Gegen den Strom\\n\\nErstes Kapitel.\\n\\nEs war z...  \n",
       "7  San Benedettos Dornen und San Francescos Rosen...  \n",
       "8  Eine teure Depesche\\n\\nSie saßen wieder zu dri...  \n",
       "9  Das Heiratsjahr.\\n\\nErstes Kapitel.\\n\\nIn welc...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 10 lines of the data frame\n",
    "d_prose_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102204c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name\n",
      "document_text\n"
     ]
    }
   ],
   "source": [
    "# Get the headers of each column\n",
    "headers_d_prose = d_prose_texts.columns.tolist()\n",
    "\n",
    "# Print the column headers\n",
    "for header in headers_d_prose:\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd41e497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>document_text</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...</td>\n",
       "      <td>Der Raritätenliabhaber\\n\\n»Ja, grüaß Eahna Got...</td>\n",
       "      <td>Der Raritätenliabhaber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...</td>\n",
       "      <td>Die Neunte in Klütenbüttel\\n\\nIn Klütenbüttel ...</td>\n",
       "      <td>Die Neunte in Klütenbüttel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anzengruber_Ludwig_Kalendergeschichten_Treff-A...</td>\n",
       "      <td>Treff-Aß\\n\\nGibt es ein Buch des Schicksals, s...</td>\n",
       "      <td>Treff-Aß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fontane_Theodor_Cecile.txt</td>\n",
       "      <td>Cécile\\n\\nErstes Kapitel\\n\\n»Thale. Zweiter…«\\...</td>\n",
       "      <td>Cécile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...</td>\n",
       "      <td>Die Perlmutterstadt\\n\\nBekanntlich weilt der u...</td>\n",
       "      <td>Die Perlmutterstadt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hollaender_Felix_Die_Briefe_des_Fraeulein.txt</td>\n",
       "      <td>Die Briefe des Fräulein Brandt\\n\\nIserbaude, 7...</td>\n",
       "      <td>Die Briefe des Fräulein Brandt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heyse_Paul_Gegen_den_Strom.txt</td>\n",
       "      <td>Gegen den Strom\\n\\nErstes Kapitel.\\n\\nEs war z...</td>\n",
       "      <td>Gegen den Strom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Federer_Heinrich_Umbrische_Reisegeschichtlein_...</td>\n",
       "      <td>San Benedettos Dornen und San Francescos Rosen...</td>\n",
       "      <td>San Benedettos Dornen und San Francescos Rosen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Groller_Balduin_Detektiv_Dagobert_Eine_teure_D...</td>\n",
       "      <td>Eine teure Depesche\\n\\nSie saßen wieder zu dri...</td>\n",
       "      <td>Eine teure Depesche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>von_Zobeltitz_Fedor_Das_Heiratsjahr.txt</td>\n",
       "      <td>Das Heiratsjahr.\\n\\nErstes Kapitel.\\n\\nIn welc...</td>\n",
       "      <td>Das Heiratsjahr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0  von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...   \n",
       "1  Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...   \n",
       "2  Anzengruber_Ludwig_Kalendergeschichten_Treff-A...   \n",
       "3                         Fontane_Theodor_Cecile.txt   \n",
       "4  Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...   \n",
       "5      Hollaender_Felix_Die_Briefe_des_Fraeulein.txt   \n",
       "6                     Heyse_Paul_Gegen_den_Strom.txt   \n",
       "7  Federer_Heinrich_Umbrische_Reisegeschichtlein_...   \n",
       "8  Groller_Balduin_Detektiv_Dagobert_Eine_teure_D...   \n",
       "9            von_Zobeltitz_Fedor_Das_Heiratsjahr.txt   \n",
       "\n",
       "                                       document_text  \\\n",
       "0  Der Raritätenliabhaber\\n\\n»Ja, grüaß Eahna Got...   \n",
       "1  Die Neunte in Klütenbüttel\\n\\nIn Klütenbüttel ...   \n",
       "2  Treff-Aß\\n\\nGibt es ein Buch des Schicksals, s...   \n",
       "3  Cécile\\n\\nErstes Kapitel\\n\\n»Thale. Zweiter…«\\...   \n",
       "4  Die Perlmutterstadt\\n\\nBekanntlich weilt der u...   \n",
       "5  Die Briefe des Fräulein Brandt\\n\\nIserbaude, 7...   \n",
       "6  Gegen den Strom\\n\\nErstes Kapitel.\\n\\nEs war z...   \n",
       "7  San Benedettos Dornen und San Francescos Rosen...   \n",
       "8  Eine teure Depesche\\n\\nSie saßen wieder zu dri...   \n",
       "9  Das Heiratsjahr.\\n\\nErstes Kapitel.\\n\\nIn welc...   \n",
       "\n",
       "                                           titles  \n",
       "0                          Der Raritätenliabhaber  \n",
       "1                      Die Neunte in Klütenbüttel  \n",
       "2                                        Treff-Aß  \n",
       "3                                          Cécile  \n",
       "4                             Die Perlmutterstadt  \n",
       "5                  Die Briefe des Fräulein Brandt  \n",
       "6                                 Gegen den Strom  \n",
       "7  San Benedettos Dornen und San Francescos Rosen  \n",
       "8                             Eine teure Depesche  \n",
       "9                                Das Heiratsjahr.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the title of the text as a further column with metadata\n",
    "\n",
    "\n",
    "# Define the regular expression pattern to extract the title followed by double line break \\n\\n\n",
    "pattern = r'^(.*?)\\n\\n'\n",
    "\n",
    "# Extract the first line and create a new 'titles' column\n",
    "d_prose_texts['titles'] = d_prose_texts['document_text'].str.extract(pattern, flags=re.DOTALL)\n",
    "\n",
    "# Print the DataFrame to see the results\n",
    "d_prose_texts[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f6441",
   "metadata": {},
   "source": [
    "now, you can see still some \\n\\n these are line breaks. You can use regular expressions to extract the first line as title of the text. And the file name contains the name of the author, but that is not as easy to extract. Better to be extracted from the metadata with a comparison of filename and filename indicated in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8c1f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_9648/219875720.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  d_prose_texts['clean_text'] = d_prose_texts['document_text'].str.replace('\\s+', ' ') # remove double white space\n",
      "/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_9648/219875720.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  d_prose_texts['clean_text'] = d_prose_texts['clean_text'].str.replace('\\n+', '\\n') # remove double line break\n"
     ]
    }
   ],
   "source": [
    "#create a new column\n",
    "#use regular expressions to clean the plain text and store the cleaned text in a new column as a further layer of the text without deleting the original version\n",
    "d_prose_texts['clean_text'] = d_prose_texts['document_text'].str.replace('\\s+', ' ') # remove double white space\n",
    "d_prose_texts['clean_text'] = d_prose_texts['clean_text'].str.replace('\\n+', '\\n') # remove double line break\n",
    "d_prose_texts['clean_text'] = d_prose_texts['clean_text'].str.replace('&', 'and') # exchange & for 'and'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3dabc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prose_texts['clean_text_lower'] = d_prose_texts['clean_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750d936a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>document_text</th>\n",
       "      <th>titles</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...</td>\n",
       "      <td>Der Raritätenliabhaber\\n\\n»Ja, grüaß Eahna Got...</td>\n",
       "      <td>Der Raritätenliabhaber</td>\n",
       "      <td>Der Raritätenliabhaber »Ja, grüaß Eahna Gott, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...</td>\n",
       "      <td>Die Neunte in Klütenbüttel\\n\\nIn Klütenbüttel ...</td>\n",
       "      <td>Die Neunte in Klütenbüttel</td>\n",
       "      <td>Die Neunte in Klütenbüttel In Klütenbüttel sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anzengruber_Ludwig_Kalendergeschichten_Treff-A...</td>\n",
       "      <td>Treff-Aß\\n\\nGibt es ein Buch des Schicksals, s...</td>\n",
       "      <td>Treff-Aß</td>\n",
       "      <td>Treff-Aß Gibt es ein Buch des Schicksals, so k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fontane_Theodor_Cecile.txt</td>\n",
       "      <td>Cécile\\n\\nErstes Kapitel\\n\\n»Thale. Zweiter…«\\...</td>\n",
       "      <td>Cécile</td>\n",
       "      <td>Cécile Erstes Kapitel »Thale. Zweiter…« »Letzt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...</td>\n",
       "      <td>Die Perlmutterstadt\\n\\nBekanntlich weilt der u...</td>\n",
       "      <td>Die Perlmutterstadt</td>\n",
       "      <td>Die Perlmutterstadt Bekanntlich weilt der ural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hollaender_Felix_Die_Briefe_des_Fraeulein.txt</td>\n",
       "      <td>Die Briefe des Fräulein Brandt\\n\\nIserbaude, 7...</td>\n",
       "      <td>Die Briefe des Fräulein Brandt</td>\n",
       "      <td>Die Briefe des Fräulein Brandt Iserbaude, 7. J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heyse_Paul_Gegen_den_Strom.txt</td>\n",
       "      <td>Gegen den Strom\\n\\nErstes Kapitel.\\n\\nEs war z...</td>\n",
       "      <td>Gegen den Strom</td>\n",
       "      <td>Gegen den Strom Erstes Kapitel. Es war zu Anfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Federer_Heinrich_Umbrische_Reisegeschichtlein_...</td>\n",
       "      <td>San Benedettos Dornen und San Francescos Rosen...</td>\n",
       "      <td>San Benedettos Dornen und San Francescos Rosen</td>\n",
       "      <td>San Benedettos Dornen und San Francescos Rosen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Groller_Balduin_Detektiv_Dagobert_Eine_teure_D...</td>\n",
       "      <td>Eine teure Depesche\\n\\nSie saßen wieder zu dri...</td>\n",
       "      <td>Eine teure Depesche</td>\n",
       "      <td>Eine teure Depesche Sie saßen wieder zu dritt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>von_Zobeltitz_Fedor_Das_Heiratsjahr.txt</td>\n",
       "      <td>Das Heiratsjahr.\\n\\nErstes Kapitel.\\n\\nIn welc...</td>\n",
       "      <td>Das Heiratsjahr.</td>\n",
       "      <td>Das Heiratsjahr. Erstes Kapitel. In welchem si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0  von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...   \n",
       "1  Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...   \n",
       "2  Anzengruber_Ludwig_Kalendergeschichten_Treff-A...   \n",
       "3                         Fontane_Theodor_Cecile.txt   \n",
       "4  Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...   \n",
       "5      Hollaender_Felix_Die_Briefe_des_Fraeulein.txt   \n",
       "6                     Heyse_Paul_Gegen_den_Strom.txt   \n",
       "7  Federer_Heinrich_Umbrische_Reisegeschichtlein_...   \n",
       "8  Groller_Balduin_Detektiv_Dagobert_Eine_teure_D...   \n",
       "9            von_Zobeltitz_Fedor_Das_Heiratsjahr.txt   \n",
       "\n",
       "                                       document_text  \\\n",
       "0  Der Raritätenliabhaber\\n\\n»Ja, grüaß Eahna Got...   \n",
       "1  Die Neunte in Klütenbüttel\\n\\nIn Klütenbüttel ...   \n",
       "2  Treff-Aß\\n\\nGibt es ein Buch des Schicksals, s...   \n",
       "3  Cécile\\n\\nErstes Kapitel\\n\\n»Thale. Zweiter…«\\...   \n",
       "4  Die Perlmutterstadt\\n\\nBekanntlich weilt der u...   \n",
       "5  Die Briefe des Fräulein Brandt\\n\\nIserbaude, 7...   \n",
       "6  Gegen den Strom\\n\\nErstes Kapitel.\\n\\nEs war z...   \n",
       "7  San Benedettos Dornen und San Francescos Rosen...   \n",
       "8  Eine teure Depesche\\n\\nSie saßen wieder zu dri...   \n",
       "9  Das Heiratsjahr.\\n\\nErstes Kapitel.\\n\\nIn welc...   \n",
       "\n",
       "                                           titles  \\\n",
       "0                          Der Raritätenliabhaber   \n",
       "1                      Die Neunte in Klütenbüttel   \n",
       "2                                        Treff-Aß   \n",
       "3                                          Cécile   \n",
       "4                             Die Perlmutterstadt   \n",
       "5                  Die Briefe des Fräulein Brandt   \n",
       "6                                 Gegen den Strom   \n",
       "7  San Benedettos Dornen und San Francescos Rosen   \n",
       "8                             Eine teure Depesche   \n",
       "9                                Das Heiratsjahr.   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Der Raritätenliabhaber »Ja, grüaß Eahna Gott, ...  \n",
       "1  Die Neunte in Klütenbüttel In Klütenbüttel sol...  \n",
       "2  Treff-Aß Gibt es ein Buch des Schicksals, so k...  \n",
       "3  Cécile Erstes Kapitel »Thale. Zweiter…« »Letzt...  \n",
       "4  Die Perlmutterstadt Bekanntlich weilt der ural...  \n",
       "5  Die Briefe des Fräulein Brandt Iserbaude, 7. J...  \n",
       "6  Gegen den Strom Erstes Kapitel. Es war zu Anfa...  \n",
       "7  San Benedettos Dornen und San Francescos Rosen...  \n",
       "8  Eine teure Depesche Sie saßen wieder zu dritt ...  \n",
       "9  Das Heiratsjahr. Erstes Kapitel. In welchem si...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 10 lines of the data frame\n",
    "d_prose_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "180fb135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'Brief' or 'Briefe': 1260\n"
     ]
    }
   ],
   "source": [
    "# Check how often the word Brief, or Briefe or Briefchen appears in the corpus.\n",
    "\n",
    "def count_brief_frequency(corpus):\n",
    "    # Combine the corpus into a single string\n",
    "    combined_text = ' '.join(corpus)\n",
    "    \n",
    "    # Regular expression to match \"Brief\" or \"Briefe\"\n",
    "    brief_pattern = r'[Bb]rief[e]? von'\n",
    "    #brief_pattern = r'Briefchen'\n",
    "    \n",
    "    # Count the frequency of matches\n",
    "    brief_count = len(re.findall(brief_pattern, combined_text))\n",
    "    \n",
    "    return brief_count\n",
    "\n",
    "# Example corpus (replace with your actual corpus)\n",
    "corpus = d_prose_texts['clean_text']\n",
    "\n",
    "# Count the frequency of \"Brief\" or \"Briefe\"\n",
    "frequency = count_brief_frequency(corpus)\n",
    "print(f\"Frequency of 'Brief' or 'Briefe': {frequency}\")\n",
    "#Frequency of 'Brief' or 'Briefe': 4760\n",
    "#Frequency of 'Briefchen': 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e2282d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          random_text\n",
      "0   Das Tanzlegendchen Nach der Aufzeichnung des h...\n",
      "1   Das verlorne Lachen Erstes Kapitel Drei Ellen ...\n",
      "2   SELIGE LIEBE. Dein Löwenhaupt sitzt auf einem ...\n",
      "3   Mutter und Tochter Zwischen den stattlichen Bä...\n",
      "4   Die bayrische Königstragödie im Bürgerhause Di...\n",
      "5   Im alten Eisen Erstes Kapitel Solange der Mens...\n",
      "6   Die ewige Burg I. Ein leiser, sonderbarer unna...\n",
      "7   Der Schlangenmensch Verrenkungsstudie von Hobb...\n",
      "8   Grausam. I. Weißt Du noch, wie wir einst als K...\n",
      "9   Vater Mein Vater starb plötzlich. Wir waren vo...\n",
      "10  Es fiel ein Reif in der Frühlingsnacht Blanche...\n",
      "11  Ein königlicher Kaufmann I Der Wortführer der ...\n",
      "12  Sturm Über dem schmalen Inselstreifen, der sic...\n",
      "13  Crone Stäudlin Im waldigsten Teile eines mitte...\n",
      "14  Odhins Rache I. Still, wie träumend in trauers...\n",
      "15  Kaspar Asam Hinauf und hinunter führte der Leb...\n",
      "16  Eine Romanheldin Kürzlich begegnete ich in der...\n",
      "17  Meister Robinson Der Garten an der Elbe In der...\n",
      "18  Der wilde Starost und die schöne Jütta Es ist ...\n",
      "19  Božena 1 Leopold Heißenstein war der reichste ...\n",
      "20  Brief an den Vater Liebster Vater, Du hast mic...\n",
      "21  Professor Hardtmut Charakterstudie »Daß es auc...\n",
      "22  Der Monarch Es war im Hochsommer, als ich ihn ...\n",
      "23  Hetzjagd In dem mir bekannten Waldkrug hatte i...\n",
      "24  Meta Meta war dienender Geist, geboren im glei...\n",
      "25  Am Hof des Tyrannen Die schöne Galatea war heu...\n",
      "26  Die Zeit Dreißig Maate und Matrosen marschiert...\n",
      "27  Unter der Windhose Es war ein wunderbar schöne...\n",
      "28  Am Graben Unter dem Galgenberge mündet ein Gra...\n",
      "29   Der Riesenmaulwurf Diejenigen, ich gehöre zu ...\n",
      "30  Mädchenlose Erstes Kapitel. Heilige Stunden. E...\n",
      "31  Der Vampir In die weitgeöffneten Fenster meine...\n",
      "32  Die Heirat des Herrn Stäudl I. »Danke, Herr La...\n",
      "33  Der Staatsanwalt Duncker Am Stammtisch im Hote...\n",
      "34  Sein Verstand Sein Verstand. So nannten ihn al...\n",
      "35  Raubmenschen Rennewart Rennewart war ein Mann,...\n",
      "36  Ein scandalöser Fall Das säkularisirte Kloster...\n",
      "37  Gelobt sei Gott Das Haus des Lebens, wie die J...\n",
      "38  Der Heidweg Tag für Tag gehe ich denselben Weg...\n",
      "39  Im Wollteufel »Gut, es soll reihum ein Jeder e...\n",
      "40  Bracke Wer bist du? Tritt näher, daß ich dir i...\n",
      "41  Glasmacherleut' I. Osterferien! Reizendes Wort...\n",
      "42  Ein Abschied Eine Stunde wartete er schon. Das...\n",
      "43  Der Untergang Chlodwig Dohna, ein nervöser Men...\n",
      "44  Die Martinsklause Erster Band 1 Eine stille So...\n",
      "45  Der gute Mond Vor vierzehn Tagen haben wir ihn...\n",
      "46  Drei Brüder suchen das Glück Portier Breise »Ü...\n",
      "47  Der Traum des Kommandeurs Der Korpskommandeur ...\n",
      "48  Gänseliesel. Erstes Kapitel. »Ihr Gänschen, da...\n",
      "49  Die Jungfrau und der Teufel Es war ein Graf Ge...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Select 50 random texts\n",
    "random_texts = random.sample(d_prose_texts['clean_text'].tolist(), 50)\n",
    "\n",
    "# Create a subdataframe from the randomly chosen texts\n",
    "subdata = pd.DataFrame({'random_text': random_texts})\n",
    "\n",
    "# Print the subdataframe\n",
    "print(subdata)\n",
    "\n",
    "#Save random sample to a new CSV file\n",
    "subdata.to_csv('random_sample_d_prose_clean_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547c1ab",
   "metadata": {},
   "source": [
    "End of the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd5680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6da8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d4644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2587301e",
   "metadata": {},
   "source": [
    "Now we want to find out more about the texts in our corpus. \n",
    "For instance, we want to find out if there are letters in the corpus texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2d161a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>Brief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>Brief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2511 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0       NaN\n",
       "1       NaN\n",
       "2     Brief\n",
       "3     Brief\n",
       "4       NaN\n",
       "...     ...\n",
       "2506  Brief\n",
       "2507    NaN\n",
       "2508  Brief\n",
       "2509    NaN\n",
       "2510    NaN\n",
       "\n",
       "[2511 rows x 1 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional: try different regular expressions to extract content from inbetween xml-tags\n",
    "# with the given xml-tag you extract the titles of the periodicals in the corpus\n",
    "#d_prose_texts['clean_text'].str.extract(r'(liebe)')#[1]\n",
    "d_prose_texts['clean_text'].str.extract(r'(Brief)')#[1]\n",
    "# use the index [1] to extract only the one column that contains the content between the xml-tags and not the column with indicated xml-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bd4d59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load your corpus data into a DataFrame (assuming the corpus is in a CSV file)\n",
    "#corpus_data = pd.read_csv('your_corpus_file.csv')\n",
    "\n",
    "# Define a function to extract the desired text around the keyword\n",
    "def extract_context_around_keyword(text, keyword, tokens_before, tokens_after):\n",
    "    keyword_indices = [i for i, token in enumerate(text) if token == keyword]\n",
    "    \n",
    "    extracted_texts = []\n",
    "    for keyword_index in keyword_indices:\n",
    "        start_index = max(0, keyword_index - tokens_before)\n",
    "        end_index = min(len(text), keyword_index + len(keyword) + tokens_after)\n",
    "        extracted_text = ' '.join(text[start_index:end_index])\n",
    "        extracted_texts.append(extracted_text)\n",
    "    \n",
    "    return extracted_texts\n",
    "\n",
    "# Tokenize the 'clean_text' column and create a new column 'tokenized_text'\n",
    "d_prose_texts['tokenized_text'] = d_prose_texts['clean_text'].apply(lambda x: word_tokenize(x, language='german'))\n",
    "\n",
    "# Extract context around the keyword 'Brief'\n",
    "tokens_before = 20\n",
    "tokens_after = 50\n",
    "keyword = 'Brief'\n",
    "d_prose_texts['context_around_keyword'] = d_prose_texts['tokenized_text'].apply(lambda x: extract_context_around_keyword(x, keyword, tokens_before, tokens_after))\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "d_prose_texts.to_csv('output_data_briefe.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1b9b6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prose_brief_context = d_prose_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "21d3c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del d_prose_brief_context['tokenized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "37beb34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prose_brief_context['file_name'] = d_prose_texts['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "337d04fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>titles</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>context_around_keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...</td>\n",
       "      <td>Der Raritätenliabhaber</td>\n",
       "      <td>Der Raritätenliabhaber »Ja, grüaß Eahna Gott, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...</td>\n",
       "      <td>Die Neunte in Klütenbüttel</td>\n",
       "      <td>Die Neunte in Klütenbüttel In Klütenbüttel sol...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anzengruber_Ludwig_Kalendergeschichten_Treff-A...</td>\n",
       "      <td>Treff-Aß</td>\n",
       "      <td>Treff-Aß Gibt es ein Buch des Schicksals, so k...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fontane_Theodor_Cecile.txt</td>\n",
       "      <td>Cécile</td>\n",
       "      <td>Cécile Erstes Kapitel »Thale. Zweiter…« »Letzt...</td>\n",
       "      <td>[Gruß und Kuß . Wie immer Dein Dich herzlich l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...</td>\n",
       "      <td>Die Perlmutterstadt</td>\n",
       "      <td>Die Perlmutterstadt Bekanntlich weilt der ural...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>Thoma_Ludwig_In_den_Ferien.txt</td>\n",
       "      <td>In den Ferien</td>\n",
       "      <td>In den Ferien Es ist die große Vakanz gewesen,...</td>\n",
       "      <td>[Hut auch . Dann bin ich erst heim und legte d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>Loens_Hermann_Tiergeschichten_Die_Einwanderer.txt</td>\n",
       "      <td>Die Einwanderer</td>\n",
       "      <td>Die Einwanderer »Eine dumme Geschichte das«, d...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>Spielhagen_Friedrich_Noblesse_oblige.txt</td>\n",
       "      <td>Noblesse oblige</td>\n",
       "      <td>Noblesse oblige Erstes Buch. Erstes Kapitel. D...</td>\n",
       "      <td>[ging eilig nach der Tür , schob den Riegel vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>Ganghofer_Ludwig_Fliegender_Sommer_Der_blinde_...</td>\n",
       "      <td>Der blinde Passagier</td>\n",
       "      <td>Der blinde Passagier Wir hatten uns über das u...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>May_Karl_Das_Hamail.txt</td>\n",
       "      <td>Das Hamaïl</td>\n",
       "      <td>Das Hamaïl Zwischen Bir el asuad und Ain tajib...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2511 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_name  \\\n",
       "0     von_Wolzogen_Ernst_Vom_Peperl_und von andern_R...   \n",
       "1     Ernst_Otto_Satiren_Die_Neunte_in_Kluetenbuette...   \n",
       "2     Anzengruber_Ludwig_Kalendergeschichten_Treff-A...   \n",
       "3                            Fontane_Theodor_Cecile.txt   \n",
       "4     Scheerbart_Paul_Das_grosse_Licht_Die_Perlmutte...   \n",
       "...                                                 ...   \n",
       "2506                     Thoma_Ludwig_In_den_Ferien.txt   \n",
       "2507  Loens_Hermann_Tiergeschichten_Die_Einwanderer.txt   \n",
       "2508           Spielhagen_Friedrich_Noblesse_oblige.txt   \n",
       "2509  Ganghofer_Ludwig_Fliegender_Sommer_Der_blinde_...   \n",
       "2510                            May_Karl_Das_Hamail.txt   \n",
       "\n",
       "                          titles  \\\n",
       "0         Der Raritätenliabhaber   \n",
       "1     Die Neunte in Klütenbüttel   \n",
       "2                       Treff-Aß   \n",
       "3                         Cécile   \n",
       "4            Die Perlmutterstadt   \n",
       "...                          ...   \n",
       "2506               In den Ferien   \n",
       "2507             Die Einwanderer   \n",
       "2508             Noblesse oblige   \n",
       "2509        Der blinde Passagier   \n",
       "2510                  Das Hamaïl   \n",
       "\n",
       "                                             clean_text  \\\n",
       "0     Der Raritätenliabhaber »Ja, grüaß Eahna Gott, ...   \n",
       "1     Die Neunte in Klütenbüttel In Klütenbüttel sol...   \n",
       "2     Treff-Aß Gibt es ein Buch des Schicksals, so k...   \n",
       "3     Cécile Erstes Kapitel »Thale. Zweiter…« »Letzt...   \n",
       "4     Die Perlmutterstadt Bekanntlich weilt der ural...   \n",
       "...                                                 ...   \n",
       "2506  In den Ferien Es ist die große Vakanz gewesen,...   \n",
       "2507  Die Einwanderer »Eine dumme Geschichte das«, d...   \n",
       "2508  Noblesse oblige Erstes Buch. Erstes Kapitel. D...   \n",
       "2509  Der blinde Passagier Wir hatten uns über das u...   \n",
       "2510  Das Hamaïl Zwischen Bir el asuad und Ain tajib...   \n",
       "\n",
       "                                 context_around_keyword  \n",
       "0                                                    []  \n",
       "1                                                    []  \n",
       "2                                                    []  \n",
       "3     [Gruß und Kuß . Wie immer Dein Dich herzlich l...  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "2506  [Hut auch . Dann bin ich erst heim und legte d...  \n",
       "2507                                                 []  \n",
       "2508  [ging eilig nach der Tür , schob den Riegel vo...  \n",
       "2509                                                 []  \n",
       "2510                                                 []  \n",
       "\n",
       "[2511 rows x 4 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_prose_brief_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cc5577f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prose_brief_context_9.to_csv('output_briefe_all_context_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eafcc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prose_brief_context_9 = d_prose_brief_context[2001:2511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5fc83339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    []\n",
       "1                                                    []\n",
       "2                                                    []\n",
       "3     [Gruß und Kuß . Wie immer Dein Dich herzlich l...\n",
       "4                                                    []\n",
       "5     [Juni . Aller Augen sind spannungsvoll auf mic...\n",
       "6     [, es wäre nicht geschehen , wenn ich dort gew...\n",
       "7                                                    []\n",
       "8     [! ‹ Ich dankte für das Kompliment und bat , d...\n",
       "9     [ihren Pensionsfreundinnen schrieb sie sich wö...\n",
       "10                                                   []\n",
       "11    [ihrer Tante zu überbringen. « Die bonne mère ...\n",
       "12    [, kam ein Fahrrad-Dienstmann in fliegender Ei...\n",
       "13                                                   []\n",
       "14                                                   []\n",
       "15                                                   []\n",
       "16                                                   []\n",
       "17                                                   []\n",
       "18    [hatte zurückziehen können , die Schlacht an d...\n",
       "19                                                   []\n",
       "Name: context_around_keyword, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(d_prose_texts_short)\n",
    "d_prose_texts_short['context_around_keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e294b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "del d_prose_texts_short['document_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a995baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_prose_texts_short.to_csv('output_data_briefe_auswahl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a6222085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste von Briefanfängen\n",
    "letter_openings = [\n",
    "    r'mein liebe[rsn]?',\n",
    "    r'hochverehrte[rsn]?',\n",
    "    r'geehrt[esn]?',\n",
    "    r'sehr geehrte[srn]?',\n",
    "    r'sehr verehrte[rs]?',\n",
    "    r'grüss dich',\n",
    "    r'grüß dich',\n",
    "    r'liebe[sr]?',\n",
    "    r'werter',\n",
    "    r'meine[nr]?',\n",
    "    r'mein',\n",
    "    r'mein geliebte[rs]?',\n",
    "    r'[teuerste[sr]?',\n",
    "    r'liebchen',\n",
    "    # Weitere Anfangsformulierungen hier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load your corpus data into a DataFrame (assuming the corpus is in a CSV file)\n",
    "#corpus_data = pd.read_csv('your_corpus_file.csv')\n",
    "\n",
    "# Define a function to extract the desired text around the keyword\n",
    "def extract_context_around_keyword(text, keyword, tokens_before, tokens_after):\n",
    "    keyword_indices = [i for i, token in enumerate(text) if token == keyword]\n",
    "    \n",
    "    extracted_texts = []\n",
    "    for keyword_index in keyword_indices:\n",
    "        start_index = max(0, keyword_index - tokens_before)\n",
    "        end_index = min(len(text), keyword_index + len(keyword) + tokens_after)\n",
    "        extracted_text = ' '.join(text[start_index:end_index])\n",
    "        extracted_texts.append(extracted_text)\n",
    "    \n",
    "    return extracted_texts\n",
    "\n",
    "# Tokenize the 'clean_text' column and create a new column 'tokenized_text'\n",
    "d_prose_texts['tokenized_text'] = d_prose_texts['clean_text'].apply(lambda x: word_tokenize(x, language='german'))\n",
    "\n",
    "# Extract context around the keyword 'Brief'\n",
    "tokens_before = 20\n",
    "tokens_after = 50\n",
    "keyword = 'Brief'\n",
    "d_prose_texts['context_around_keyword'] = d_prose_texts['tokenized_text'].apply(lambda x: extract_context_around_keyword(x, keyword, tokens_before, tokens_after))\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "d_prose_texts.to_csv('output_data_briefe.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69c0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfa81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ca7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5641288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae3dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905cd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f13b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049aae8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298125b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4921e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8ad1ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9283401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    clean_text_lower\n",
      "0  der raritätenliabhaber »ja, grüaß eahna gott, ...\n",
      "1  die neunte in klütenbüttel in klütenbüttel sol...\n",
      "2  treff-aß gibt es ein buch des schicksals, so k...\n",
      "3  cécile erstes kapitel »thale. zweiter…« »letzt...\n",
      "4  die perlmutterstadt bekanntlich weilt der ural...\n",
      "5  die briefe des fräulein brandt iserbaude, 7. j...\n",
      "6  gegen den strom erstes kapitel. es war zu anfa...\n",
      "7  san benedettos dornen und san francescos rosen...\n",
      "8  eine teure depesche sie saßen wieder zu dritt ...\n",
      "9  das heiratsjahr. erstes kapitel. in welchem si...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(d_prose_texts['clean_text_lower'])\n",
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f6d091a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste von Briefanfängen\n",
    "letter_openings = [\n",
    "    r'mein liebe[rsn]?',\n",
    "    r'hochverehrte[rsn]?',\n",
    "    r'geehrt[esn]?',\n",
    "    r'sehr geehrte[srn]?',\n",
    "    r'sehr verehrte[rs]?',\n",
    "    r'grüss dich',\n",
    "    r'grüß dich',\n",
    "    r'liebe[sr]?',\n",
    "    r'werter',\n",
    "    r'meine[nr]?',\n",
    "    r'mein',\n",
    "    r'mein geliebte[rs]?',\n",
    "    r'[teuerste[sr]?',\n",
    "    r'liebchen',\n",
    "    # Weitere Anfangsformulierungen hier\n",
    "]\n",
    "\n",
    "# Regulärer Ausdruck, um Briefanfänge zu erkennen\n",
    "letter_opening_pattern = r'(?:' + '|'.join(letter_openings) + r')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5614dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_sample = [\"hans! es hat mir sehr leid gethan, so lange nichts von ihnen zu hören, besonders leid, weil sie natek verlassen hatten, gerade nachdem der erste mißton in unsere freundschaft gedrungen war. ich hatte so darauf gerechnet, meinen brief mündlich zu erläutern, die schroffheiten, welche jede aufrichtigkeit mit sich bringt, zu der man sich mühsam hat zwingen müssen, wieder gut zu machen. gewiß hatten sie vor ihrer abreise keine zeit mehr, zu mir herüberzukommen, aber ein paar zeilen hätten sie mir schreiben können, nur um mir zu sagen, daß sie mir meine aufrichtigkeit nicht übel genommen haben. denken sie, anfangs glaubte ich, daß sie mir böse wären; aber jetzt verachte ich mich für den verdacht. durch zufall hab' ich erfahren, daß sie sich in wodanka, wohin sie dringender geschäftsangelegenheiten halber berufen worden sind, den fuß gebrochen haben. ich kann ihnen gar nicht sagen, wie leid sie mir thun, wie besorgt ich um sie bin. bitte, schreiben sie mir, wie es ihnen geht, wie und wann sie sich das bein gebrochen haben, wer sie behandelt, mein armer hans! … gerade sie, der sie das stillsitzen so schlecht vertragen! daß ihnen das geschehen mußte! in zwei bis drei monaten ist wohl alles in ordnung – aber zwei monate sind lang – schade darum!  kann ich ihnen in irgend etwas nützlich sein, so bitte, lieber hans, schreiben sie mir eine zeile. als barmherzige schwester stellt sich ihnen vollkommen zur verfügung ihre ihnen treu ergebene marie rheinsberg. p. s. bitte, lassen sie mich nicht auf antwort warten, ich bin sehr, sehr besorgt!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d2327ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          brief_text\n",
      "0  hans! es hat mir sehr leid gethan, so lange ni...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = pd.DataFrame(brief_sample, columns=['brief_text'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7093dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Extraktion des Briefanfangs und der folgenden 50 Zeichen\n",
    "def extract_letter_info(text):\n",
    "    match = re.search(letter_opening_pattern, text, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        letter_opening = match.group(0)\n",
    "        letter_text = text[match.end():match.end()+50].strip()\n",
    "        return letter_opening, letter_text\n",
    "    else:\n",
    "        return \"no letter\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "934fdd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (, hans! es hat mir sehr leid gethan, so lange...\n",
      "Name: brief_text_brief, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1['brief_text_brief'] = df1['brief_text'].apply(extract_letter_info)\n",
    "print(df1['brief_text_brief'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Den DataFrame um die extrahierten Briefanfänge und Texte erweitern\n",
    "df[['letter_opening', 'letter_text']] = df['clean_text'].apply(extract_letter_info)\n",
    "\n",
    "# Anzeigen der extrahierten Briefanfänge und Texte\n",
    "print(df[['clean_text', 'letter_opening', 'letter_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "52d0ddcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1002713011.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_76587/1002713011.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    letter_pattern = r'(?:' + '|'.join(letter_openings)')\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Regulärer Ausdruck, um Brieftexte zu erkennen\n",
    "letter_pattern = r'(?:' + '|'.join(letter_openings)')\n",
    "\n",
    "# Funktion zum Extrahieren der Brieftexte\n",
    "def extract_letters(text):\n",
    "    matches = re.findall(letter_pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    return matches\n",
    "\n",
    "#d_prose_briefe_test['clean_text']\n",
    "\n",
    "# Den DataFrame um die extrahierten Brieftexte erweitern\n",
    "df1['extracted_letters'] = df1['brief_text_brief'].apply(extract_letters)\n",
    "\n",
    "# Neuen DataFrame erstellen, um jeden Brieftext als eigenen Eintrag zu haben\n",
    "expanded_data = []\n",
    "for index, row in df1.iterrows():\n",
    "    for letter_text in row['extracted_letters']:\n",
    "        expanded_data.append({'file_name': row['file_name'], 'letter_text': letter_text})\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "# Anzeigen der extrahierten Brieftexte\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f4d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54e014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbaa48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab558a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79433ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6592ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1d0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bf095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a503f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Beispiel DataFrame\n",
    "#data = {   'clean_text': [\n",
    "        #\"Liebe Tante, ich hoffe es geht dir gut... Mit besten Grüßen, Max\",\n",
    "        #\"Sehr geehrter Herr Müller, in Bezug auf... Hochachtungsvoll, Anna\",\n",
    "        #\"Mein lieber Freund, wie geht es dir?... Herzliche Grüße, Paul\"\n",
    "        # Weitere Texte hier]}\n",
    "\n",
    "\n",
    "texte = pd.DataFrame(d_prose_texts['clean_text'])\n",
    "\n",
    "# Liste von Briefanfängen und -enden\n",
    "letter_openings = [\n",
    "    r'Mein [lL]iebe[rsn]?',\n",
    "    r'Hochverehrte[rsn]?',\n",
    "    r'Geehrt[esn]?',\n",
    "    r'Sehr geehrte[srn]?',\n",
    "    r'Sehr verehrte[rs]?',\n",
    "    r'Grüss dich',\n",
    "    r'Grüß dich',\n",
    "    r'Liebe[sr]?',\n",
    "    r'Werter?',\n",
    "    r'Meine[nr]?',\n",
    "    r'Mein',\n",
    "    r'Mein geliebte[rs]?',\n",
    "    r'[tT]euerste[sr]?',\n",
    "    r'Liebchen',\n",
    "    # Weitere Anfangsformulierungen hier\n",
    "]\n",
    "\n",
    "letter_closings = [\n",
    "    r'Hochachtungsvoll',\n",
    "    r'In aufrichtiger Verbundenheit',\n",
    "    r'Mit besten Grüßen',\n",
    "    r'Herzliche Grüße',\n",
    "    r'In aufrichtiger Verbundenheit',\n",
    "    r'In treuer Liebe',\n",
    "    r'Dein[e]?',\n",
    "    r'Mit vorzüglicher Hochachtung',\n",
    "    r'P. S.',\n",
    "    r'treu ergeben[e]?',\n",
    "    r'Ihr[e]?',\n",
    "    r'Segenswünsche von Deine[rm]?',\n",
    "    # Weitere Endformulierungen hier\n",
    "]\n",
    "\n",
    "# Regulärer Ausdruck, um den gesamten Brieftext zu erkennen\n",
    "letter_pattern = r'(?:(?:' + '|'.join(letter_openings) + r').*?(?:' + '|'.join(letter_closings) + r'))'\n",
    "\n",
    "# Funktion zum Extrahieren des Brieftexts\n",
    "def extract_letter(text):\n",
    "    match = re.search(letter_pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Den DataFrame um die extrahierten Briefe erweitern\n",
    "d_prose_briefe_test['extracted_letter'] = d_prose_briefe_test['clean_text'].apply(extract_letter)\n",
    "\n",
    "# Anzeigen der extrahierten Briefe\n",
    "print(d_prose_briefe_test[['clean_text', 'extracted_letter']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42fd2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df = pd.DataFrame(d_prose_texts['clean_text_lower'])\n",
    "df_sub = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46747307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    clean_text_lower\n",
      "0  der raritätenliabhaber »ja, grüaß eahna gott, ...\n",
      "1  die neunte in klütenbüttel in klütenbüttel sol...\n",
      "2  treff-aß gibt es ein buch des schicksals, so k...\n"
     ]
    }
   ],
   "source": [
    "print(df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1972ac4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a85c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    clean_text_lower\n",
      "0  der raritätenliabhaber »ja, grüaß eahna gott, ...\n",
      "1  die neunte in klütenbüttel in klütenbüttel sol...\n",
      "2  treff-aß gibt es ein buch des schicksals, so k...\n",
      "3  cécile erstes kapitel »thale. zweiter…« »letzt...\n",
      "4  die perlmutterstadt bekanntlich weilt der ural...\n",
      "5  die briefe des fräulein brandt iserbaude, 7. j...\n",
      "6  gegen den strom erstes kapitel. es war zu anfa...\n",
      "7  san benedettos dornen und san francescos rosen...\n",
      "8  eine teure depesche sie saßen wieder zu dritt ...\n",
      "9  das heiratsjahr. erstes kapitel. in welchem si...\n"
     ]
    }
   ],
   "source": [
    "print(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec89c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Liste von Briefanfängen\n",
    "letter_openings = [\n",
    "    r'mein liebe[rsn]?',\n",
    "    r'hochverehrte[rsn]?',\n",
    "    r'geehrt[esn]?',\n",
    "    r'sehr geehrte[srn]?',\n",
    "    r'sehr verehrte[rs]?',\n",
    "    r'grüss dich',\n",
    "    r'grüß dich',\n",
    "    r'liebe[sr]?',\n",
    "    r'werter',\n",
    "    r'meine[nr]?',\n",
    "    r'mein',\n",
    "    r'mein geliebte[rs]?',\n",
    "    r'[teuerste[sr]?',\n",
    "    r'liebchen',\n",
    "    # Weitere Anfangsformulierungen hier\n",
    "]\n",
    "\n",
    "\n",
    "# Regulärer Ausdruck, um Briefanfänge zu erkennen\n",
    "letter_opening_pattern = r'(?:' + '|'.join(letter_openings) + r')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50130da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Extraktion des Briefanfangs und der folgenden 50 Tokens\n",
    "def extract_letter_opening_and_tokens(text):\n",
    "    if text is None or text.strip() == \"\":\n",
    "        return [\"no letter\"]\n",
    "    \n",
    "    matches = re.finditer(letter_opening_pattern, text, flags=re.IGNORECASE)\n",
    "    results = []\n",
    "    tokens = word_tokenize(text)  \n",
    "    \n",
    "    for match in matches:\n",
    "        start_index = tokens.index(match.group(0).lower())\n",
    "        letter_opening = match.group(0)\n",
    "        following_tokens = ' '.join(tokens[start_index:start_index+51])\n",
    "        results.append((letter_opening, following_tokens))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "936208b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_76587/459181916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Den DataFrame um die extrahierten Briefanfänge und Tokens erweitern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extracted_info'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text_lower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_letter_opening_and_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_76587/1848776500.py\u001b[0m in \u001b[0;36mextract_letter_opening_and_tokens\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mletter_opening\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mfollowing_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '' is not in list"
     ]
    }
   ],
   "source": [
    "# Den DataFrame um die extrahierten Briefanfänge und Tokens erweitern\n",
    "df_sub['extracted_info'] = df_sub['clean_text_lower'].apply(extract_letter_opening_and_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a07692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen der extrahierten Briefanfänge und folgenden Tokens\n",
    "print(df_sub[['clean_text', 'extracted_info']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5e77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac727a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e8d7a3",
   "metadata": {},
   "source": [
    "Now we want to find out more about the texts in our corpus. \n",
    "For instance, we want to find out if there are letters in the corpus texts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209e151e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\n# Regular expression pattern\\npattern = r\"Lieber\\\\s[\\\\w\\\\s]+,.*?Deine,\\\\s[\\\\w\\\\s]+\"\\n\\n# Find letter passages in the prose text \\nletters = re.findall(pattern, prose_text, re.DOTALL)\\n\\n# Print the extracted letter passages\\nfor letter in letters:\\n    print(letter)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular expression pattern\n",
    "pattern = r\"Lieber\\s[\\w\\s]+,.*?Deine,\\s[\\w\\s]+\"\n",
    "\n",
    "# Find letter passages in the prose text \n",
    "letters = re.findall(pattern, prose_text, re.DOTALL)\n",
    "\n",
    "# Print the extracted letter passages\n",
    "for letter in letters:\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f58dc312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Raritätenliabhaber »Ja, grüaß Eahna Gott, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Neunte in Klütenbüttel In Klütenbüttel sol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text\n",
       "0  Der Raritätenliabhaber »Ja, grüaß Eahna Gott, ...\n",
       "1  Die Neunte in Klütenbüttel In Klütenbüttel sol..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte = pd.DataFrame(d_prose_texts['clean_text'])\n",
    "texte[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1fd64d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_40182/4157793931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Den DataFrame um die extrahierten Briefe erweitern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0md_prose_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extracted_letter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_prose_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Anzeigen der extrahierten Briefe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_40182/4157793931.py\u001b[0m in \u001b[0;36mextract_letter\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Funktion zum Extrahieren des Brieftexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Beispiel DataFrame\n",
    "#data = {   'clean_text': [\n",
    "        #\"Liebe Tante, ich hoffe es geht dir gut... Mit besten Grüßen, Max\",\n",
    "        #\"Sehr geehrter Herr Müller, in Bezug auf... Hochachtungsvoll, Anna\",\n",
    "        #\"Mein lieber Freund, wie geht es dir?... Herzliche Grüße, Paul\"\n",
    "        # Weitere Texte hier]}\n",
    "\n",
    "\n",
    "texte = pd.DataFrame(d_prose_texts['clean_text'])\n",
    "\n",
    "# Liste von Briefanfängen und -enden\n",
    "letter_openings = [\n",
    "    r'Mein [lL]iebe[rsn]?',\n",
    "    r'Hochverehrte[rsn]?',\n",
    "    r'Geehrt[esn]?',\n",
    "    r'Sehr geehrt[esn]?',\n",
    "    r'Lieb[e]?',\n",
    "    r'Werter?',\n",
    "    r'Meine[nr]?',\n",
    "    # Weitere Anfangsformulierungen hier\n",
    "]\n",
    "\n",
    "letter_closings = [\n",
    "    r'Hochachtungsvoll',\n",
    "    r'In aufrichtiger Verbundenheit',\n",
    "    r'Mit besten Grüßen',\n",
    "    r'Herzliche Grüße',\n",
    "    r'In aufrichtiger Verbundenheit',\n",
    "    r'Mit vorzüglicher Hochachtung',\n",
    "    # Weitere Endformulierungen hier\n",
    "]\n",
    "\n",
    "# Regulärer Ausdruck, um den gesamten Brieftext zu erkennen\n",
    "letter_pattern = r'(?:(?:' + '|'.join(letter_openings) + r').*?(?:' + '|'.join(letter_closings) + r'))'\n",
    "\n",
    "# Funktion zum Extrahieren des Brieftexts\n",
    "def extract_letter(text):\n",
    "    match = re.search(letter_pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Den DataFrame um die extrahierten Briefe erweitern\n",
    "d_prose_texts['extracted_letter'] = d_prose_texts['clean_text'].apply(extract_letter)\n",
    "\n",
    "# Anzeigen der extrahierten Briefe\n",
    "print(d_prose_texts[['clean_text', 'extracted_letter']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hallo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1503ec4",
   "metadata": {},
   "source": [
    "This code extracts one letter for each text entry. It looks for the letter opening patterns using regular expressions and then extracts the following 50 characters as the letter text. The DataFrame is then extended to include columns for the extracted letter opening and letter text. This should provide the desired output with a simplified approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ffbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Beispiel DataFrame (ersetzen Sie dies durch Ihren eigenen DataFrame)\n",
    "data = {\n",
    "    'clean_text': [\n",
    "        \"Liebe Tante, ich hoffe es geht dir gut... Mit besten Grüßen, Max. Hochachtungsvoll, Anna.\",\n",
    "        \"Sehr geehrter Herr Müller, in Bezug auf... Hochachtungsvoll, Anna\",\n",
    "        \"Mein lieber Freund, wie geht es dir?... Herzliche Grüße, Paul\",\n",
    "        # Weitere Texte hier\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa7f32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.DataFrame(d_prose_texts['clean_text_lower'])\n",
    "df_sub = df[:10]\n",
    "\n",
    "# Liste von Briefanfängen\n",
    "letter_openings = [\n",
    "    r'mein liebe[rsn]?',\n",
    "    r'hochverehrte[rsn]?',\n",
    "    r'geehrt[esn]?',\n",
    "    r'sehr geehrte[srn]?',\n",
    "    r'sehr verehrte[rs]?',\n",
    "    r'grüss dich',\n",
    "    r'grüß dich',\n",
    "    r'liebe[sr]?',\n",
    "    r'werter',\n",
    "    r'meine[nr]?',\n",
    "    r'mein',\n",
    "    r'mein geliebte[rs]?',\n",
    "    r'[teuerste[sr]?',\n",
    "    r'liebchen',\n",
    "    # Weitere Anfangsformulierungen hier\n",
    "]\n",
    "\n",
    "# Regulärer Ausdruck, um Briefanfänge zu erkennen\n",
    "letter_opening_pattern = r'(?:' + '|'.join(letter_openings) + r')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb685e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Extraktion des Briefanfangs und der folgenden 50 Zeichen\n",
    "def extract_letter_info(text):\n",
    "    match = re.search(letter_opening_pattern, text, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        letter_opening = match.group(0)\n",
    "        letter_text = text[match.end():match.end()+50].strip()\n",
    "        return letter_opening, letter_text\n",
    "    else:\n",
    "        return \"no letter\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a5870ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'clean_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clean_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_76587/3463303160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Den DataFrame um die extrahierten Briefanfänge und Texte erweitern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'letter_opening'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_letter_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Anzeigen der extrahierten Briefanfänge und Texte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter_opening'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clean_text'"
     ]
    }
   ],
   "source": [
    "# Den DataFrame um die extrahierten Briefanfänge und Texte erweitern\n",
    "df[['letter_opening', 'letter_text']] = df_sub['clean_text'].apply(extract_letter_info)\n",
    "\n",
    "# Anzeigen der extrahierten Briefanfänge und Texte\n",
    "print(df[['clean_text', 'letter_opening', 'letter_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3443be9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['letter_opening', 'letter_text'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qf/cmgr81q1733_dshx90_j6r9c0000gp/T/ipykernel_76587/3780871363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Anzeigen der extrahierten Briefanfänge und Texte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text_lower'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter_opening'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'letter_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['letter_opening', 'letter_text'] not in index\""
     ]
    }
   ],
   "source": [
    "# Anzeigen der extrahierten Briefanfänge und Texte\n",
    "print(df[['clean_text_lower', 'letter_opening', 'letter_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96294f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
